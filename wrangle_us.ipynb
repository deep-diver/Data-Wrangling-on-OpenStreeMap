{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling with Open Street Map(OSM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Choose a city\n",
    "- OSM includes lots of cities spread globally. \n",
    "- I could choose cities in Asia, but lots of information in written in their local languages.\n",
    "- I am going to examine **Seattle WA, USA** since it is suitable to begin to wrangle with OSM at first.\n",
    "- After getting done with this one, I will go for another cities like Seoul in S.Korea or Tokyo in Japan.\n",
    "\n",
    "![map_region_seattle](map_region_seattle.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-1. Map Information\n",
    "- I am going to download map data (.osm) from MapZen. This website provides already prepared data file for popular cities. \n",
    "  - (https://goo.gl/kXjffY for Seattle WA, USA)\n",
    "- When downloading OSM file, it is initially compressed.\n",
    "- I need to uncompress the file first"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  2. Extract sample data from original\n",
    "- Because uncompressed file is too large (> 1GB), it is hard to test code with it.\n",
    "- In order to test functions to be in my code, I need to make sample data file extracted from the original\n",
    "- The function below will do the trick."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "OSM_FILE = \"seattle_washington.osm\"  \n",
    "\n",
    "# Sample generation related\n",
    "SAMPLE_FILE = \"seattle_washington_sample_500.osm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameter: take every k-th top level element\n",
    "k = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_element(osm_file, tags=('node', 'way', 'relation')):\n",
    "    context = iter(ET.iterparse(osm_file, events=('start', 'end')))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end' and elem.tag in tags:\n",
    "            yield elem\n",
    "            root.clear()\n",
    "\n",
    "def generate_sample():\n",
    "  with open(SAMPLE_FILE, 'wb') as output:\n",
    "      output.write('<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n')\n",
    "      output.write('<osm>\\n  ')\n",
    "\n",
    "      # Write every kth top level element\n",
    "      for i, element in enumerate(get_element(OSM_FILE)):\n",
    "          if i % k == 0:\n",
    "              output.write(ET.tostring(element, encoding='utf-8'))\n",
    "\n",
    "      output.write('</osm>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate sample file\n",
    "if not os.path.exists(SAMPLE_FILE):\n",
    "    generate_sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When running the code above, I would get sample data named, \"seattle_washington_sample_xxx.osm\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. OSM's XML Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You can find full description about OSM's XML here (http://wiki.openstreetmap.org/wiki/OSM_XML)\n",
    "- OSM basically consists of four kinds of element, node, way, tag, and nd.\n",
    "- Node describes a thing \n",
    "- Way describes a connection with nodes\n",
    "- Tag gives additional information for node and way elements\n",
    "- Nd is part of way element referencing the node by its id.\n",
    "- Sample structure is shown below\n",
    "```xml\n",
    "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
    "<osm version=\"0.6\" generator=\"CGImap 0.0.2\">\n",
    "    <bounds minlat=\"54.0889580\" minlon=\"12.2487570\" maxlat=\"54.0913900\" maxlon=\"12.2524800\"/>\n",
    "     <node id=\"298884269\" lat=\"54.0901746\" lon=\"12.2482632\" user=\"SvenHRO\" uid=\"46882\" visible=\"true\" version=\"1\" changeset=\"676636\" timestamp=\"2008-09-21T21:37:45Z\"/>\n",
    "     <node id=\"261728686\" lat=\"54.0906309\" lon=\"12.2441924\" user=\"PikoWinter\" uid=\"36744\" visible=\"true\" version=\"1\" changeset=\"323878\" timestamp=\"2008-05-03T13:39:23Z\"/>\n",
    "     <node id=\"1831881213\" version=\"1\" changeset=\"12370172\" lat=\"54.0900666\" lon=\"12.2539381\" user=\"lafkor\" uid=\"75625\" visible=\"true\" timestamp=\"2012-07-20T09:43:19Z\">\n",
    "         <tag k=\"name\" v=\"Neu Broderstorf\"/>\n",
    "         <tag k=\"traffic_sign\" v=\"city_limit\"/>\n",
    "     </node>\n",
    "     ...\n",
    "     <node id=\"298884272\" lat=\"54.0901447\" lon=\"12.2516513\" user=\"SvenHRO\" uid=\"46882\" visible=\"true\" version=\"1\" changeset=\"676636\" timestamp=\"2008-09-21T21:37:45Z\"/>\n",
    "     <way id=\"26659127\" user=\"Masch\" uid=\"55988\" visible=\"true\" version=\"5\" changeset=\"4142606\" timestamp=\"2010-03-16T11:47:08Z\">\n",
    "          <nd ref=\"292403538\"/>\n",
    "          <nd ref=\"298884289\"/>\n",
    "          ...\n",
    "          <nd ref=\"261728686\"/>\n",
    "          <tag k=\"highway\" v=\"unclassified\"/>\n",
    "          <tag k=\"name\" v=\"Pastower StraÃŸe\"/>\n",
    "      </way>\n",
    "</osm>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Audit elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-1. Auditing node and way elements\n",
    "- node element includes attributes...\n",
    "  - id, lat, lon, user, uid, visible, version, changeset, timestamp\n",
    "  \n",
    "- way element includes attributes...\n",
    "  - id, user, uid, visible, version, changeset, timestamp\n",
    "  \n",
    "- their attributes contain not much of human editable information\n",
    "- id, user, uid, visible, version, changeset, timestamp are all machine generated data\n",
    "- I am not going to audit these elements for now.\n",
    "- However, if I find any, I will revise this post later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-2. Auditing tag element\n",
    "- tag element is for giving addtional information to node and way elements.\n",
    "- this is mostly where user's contribution comes in, so there could be some mistakes or inconsistency.\n",
    "- since there are too many tags available, I will choose some of them to audit for now.\n",
    "  - (you can find the entire tag set here: http://wiki.openstreetmap.org/wiki/Map_Features)\n",
    "- I think the best way to audit tag element is \n",
    "  - list all possible values from current data\n",
    "  - correct inconsistencies as much as possible for now\n",
    "  - then if I encounter other unknown issues while running a program, go back to the first step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  4-2-1.  tag element where k=[maxspeed|minspeed]\n",
    "- since mph is the standard speed unit in the US, values not specified with it has to be fixed.\n",
    "- first, I am going to look up what values there are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def audit_speed(filename):\n",
    "      speed_types = []\n",
    "\n",
    "      for event, elem in ET.iterparse(filename, events=(\"start\",)):\n",
    "            if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "                  for tag in elem.iter(\"tag\"):\n",
    "                        key = tag.attrib['k']\n",
    "                        if key == 'maxspeed' or key == 'minspeed':\n",
    "                              speed_types.append(tag.attrib['v'])\n",
    "\n",
    "      return speed_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['40 mph', '25 mph', '25 mph', '25 mph', '25 mph', '35 mph', '25 mph', '25 mph', '25 mph', '25 mph', '30 mph', '100', '50', '15 mph', '50', '40 mph', '35 mph', '55 mph', '35 mph', '30 mph', '40 mph', '25 mph', '30 mph', '50', '25 mph', '25 mph', '45 mph', '35 mph', '25 mph', '25 mph', '25 mph', '15 mph', '10 mph', '35 mph', '50 mph', '25 mph', '30 mph', '30 mph', '35 mph', '55 mph', '30', '25 mph', '35 mph', '30 mph', '35 mph', '45 mph', '30 mph', '40 mph', '40 mph', '35 mph', '40 mph', '35 mph', '25 mph', '50', '45 mph', '30 mph']\n"
     ]
    }
   ],
   "source": [
    "print audit_speed(SAMPLE_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As you can see, there are some values missing the speed unit. \n",
    "- I think when the data grows larger like combining data from other countries, it is pretty important to specify what units are used to measure something.\n",
    "- I am going to make a helper function to add 'mph' to those missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_speed_unit(value):\n",
    "    if value.find('mph') > -1:\n",
    "        return value\n",
    "    else:\n",
    "        value = '{} mph'.format(value)\n",
    "        return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 mph\n",
      "20 mph\n"
     ]
    }
   ],
   "source": [
    "print update_speed_unit('20 mph')\n",
    "print update_speed_unit('20')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  4-2-2.  tag element where k=[phone]\n",
    "- phone numbers can be written in various different ways.\n",
    "- some people include national code, or others include parenthesis surrounding local code.\n",
    "- it is better if all values are stored in the same form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- First, I am going to remove all special characters including '+', '-', '(', and ')' since some people use them, but some others don't\n",
    "- Then, I will investigate list of lengths of phone number. \n",
    "- For normal phone numbers, the length should be 10 or 11. 11 is when national code is included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def audit_phone(filename):\n",
    "    phone_len = defaultdict(list)\n",
    "\n",
    "    for event, elem in ET.iterparse(filename, events=(\"start\",)):\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                key = tag.attrib['k']\n",
    "                if key == 'phone':\n",
    "                    phone_num = re.sub(r'[\\+\\(\\)\\-\\s]', '', tag.attrib['v'])\n",
    "                    phone_len[len(phone_num)].append(tag.attrib['v'])\n",
    "\n",
    "    return phone_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "phone_audit_data = audit_phone(SAMPLE_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {4: ['+1-253-'],\n",
       "             10: ['206-220-4240', '206-524-7951', '(425) 917-1417'],\n",
       "             11: ['+1 206-633-3411',\n",
       "              '+1-206-547-1961',\n",
       "              '+1 206 448-8677',\n",
       "              '+1-425-497-8868',\n",
       "              '+1 206-467-9200',\n",
       "              '+1 206 659-4043']})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phone_audit_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As you can see, there are 3 different lengths of phone numbers.\n",
    "- The length 4 is abnormal, it doesn't mean anything. I think I should get rid of it.\n",
    "- As expected, the length 10 doesn't include the national code, but the length 11 does.\n",
    "\n",
    "- I am going to define a function to update those inconsistently written phone number to uniform shape. \n",
    "  - it is going to be '+NationalCode LocalCode-3Digits-4Digits'\n",
    "- For abnormal cases, I will just return None so I can ignore later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_phone(phone_num):\n",
    "    phone_num = re.sub(r'[\\+\\(\\)\\-\\s]', '', phone_num)\n",
    "    \n",
    "    if len(phone_num) != 10 and \\\n",
    "       len(phone_num) != 11:\n",
    "            return None\n",
    "    \n",
    "    if len(phone_num) == 10:\n",
    "        phone_num = '1{}'.format(phone_num)\n",
    "    \n",
    "    phone_num_parts = []\n",
    "    phone_num_parts.append('+')\n",
    "    phone_num_parts.append(phone_num[:1])\n",
    "    phone_num_parts.append(' ')\n",
    "    phone_num_parts.append(phone_num[1:4])\n",
    "    phone_num_parts.append('-')\n",
    "    phone_num_parts.append(phone_num[4:7])\n",
    "    phone_num_parts.append('-')\n",
    "    phone_num_parts.append(phone_num[7:])\n",
    "    \n",
    "    return ''.join(phone_num_parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['+1 206-220-4240', '+1 206-524-7951', '+1 425-917-1417', '+1 206-633-3411', '+1 206-547-1961', '+1 206-448-8677', '+1 425-497-8868', '+1 206-467-9200', '+1 206-659-4043']\n"
     ]
    }
   ],
   "source": [
    "updated_phone_nums = []\n",
    "for length, phone_nums in phone_audit_data.items():\n",
    "    for phone_num in phone_nums:\n",
    "        update_phone_num = update_phone(phone_num)\n",
    "\n",
    "        if update_phone_num is not None:\n",
    "            updated_phone_nums.append(update_phone_num)\n",
    "        \n",
    "print updated_phone_nums"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  4-2-3.  tag element where k=[addr:street]\n",
    "- We use many different street names.\n",
    "- We even abbreviate those names, which makes hard to read sometimes.\n",
    "- I am going to look up what kind of street names are used, and what names drive the whole data to be inconsistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "STREET_TYPES_RE = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def audit_street_name(filename):\n",
    "    street_types = defaultdict(set)\n",
    "\n",
    "    for event, elem in ET.iterparse(filename, events=(\"start\",)):\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                key = tag.attrib['k']\n",
    "                if key == \"addr:street\":\n",
    "                    street_name = tag.attrib['v']\n",
    "                    match = STREET_TYPES_RE.search(street_name)\n",
    "                    if match:\n",
    "                        street_type = match.group()\n",
    "                        street_types[street_type].add(street_name)\n",
    "\n",
    "    return street_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Northeast',\n",
       " 'Court',\n",
       " 'South',\n",
       " 'West',\n",
       " 'Boulevard',\n",
       " 'Northwest',\n",
       " 'Way',\n",
       " 'East',\n",
       " 'Highway',\n",
       " 'Southwest',\n",
       " 'North',\n",
       " 'Southeast',\n",
       " 'Road',\n",
       " 'Spur',\n",
       " 'NW',\n",
       " 'Loop',\n",
       " 'Lane',\n",
       " 'N.',\n",
       " 'Drive',\n",
       " 'Place',\n",
       " '104',\n",
       " 'Point',\n",
       " 'WY',\n",
       " 'SW',\n",
       " 'Street',\n",
       " 'Crescent',\n",
       " 'Avenue']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audit_street_name(SAMPLE_FILE).keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Those values listed above are street name used in the last part of the full street names.\n",
    "- Ok. Now I am going to look through what full street names are for those ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#audit_street_name(SAMPLE_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here are some of the abbreviations used in the sample data and their mapped full name.\n",
    "  - NW: Northwest\n",
    "  - N.: North\n",
    "  - WY: Way\n",
    "  - SW: Southwest\n",
    "  \n",
    "- Here are some of the commonly used abbreviations\n",
    "  - NE: Northeast\n",
    "  - SE: Southeast\n",
    "  - S.: South\n",
    "  - St/St.: Street\n",
    "  - Rd/Rd.: Road\n",
    "  - Ave: Avenue\n",
    "\n",
    "- In order to update those abbreviated street names to the full name, I need to create mapping table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "STREET_TYPE_MAPPINGS = { \"St\"    :  \"Street\",\n",
    "                         \"St.\"   :  \"Street\",\n",
    "                         \"Rd\"    :  \"Road\",\n",
    "                         \"Rd.\"   :  \"Road\",\n",
    "                         \"Ave\"   :  \"Avenue\",\n",
    "                         \"SW\"    :  \"Southwest\",\n",
    "                         \"NW\"    :  \"Northwest\",\n",
    "                         \"SE\"    :  \"Southeast\",\n",
    "                         \"NE\"    :  \"Northeast\",\n",
    "                         \"S.\"    :  \"South\",\n",
    "                         \"N.\"    :  \"North\",\n",
    "                         \"WY\"    :  \"Way\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- I am going to write a function to update street name now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "STREET_TYPES_RE = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_street_name(name):\n",
    "    m = STREET_TYPES_RE.search(name)\n",
    "\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        \n",
    "        try:\n",
    "            name = re.sub(street_type, STREET_TYPE_MAPPINGS[street_type], name)\n",
    "            return name\n",
    "        except KeyError as e:\n",
    "            return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Northeast',\n",
       " 'Court',\n",
       " 'South',\n",
       " 'West',\n",
       " 'Boulevard',\n",
       " 'Northwest',\n",
       " 'Way',\n",
       " 'East',\n",
       " 'Highway',\n",
       " 'Southwest',\n",
       " 'North',\n",
       " 'Southeast',\n",
       " 'Road',\n",
       " 'Spur',\n",
       " 'Northwest',\n",
       " 'Loop',\n",
       " 'Lane',\n",
       " 'North',\n",
       " 'Drive',\n",
       " 'Place',\n",
       " '104',\n",
       " 'Point',\n",
       " 'Way',\n",
       " 'Southwest',\n",
       " 'Street',\n",
       " 'Crescent',\n",
       " 'Avenue']"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_street_name = []\n",
    "\n",
    "for street_name in audit_street_name(SAMPLE_FILE).keys():\n",
    "    updated_street_name.append(update_street_name(street_name))\n",
    "    \n",
    "updated_street_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Reorganize OSM into CSV (prepare for SQL)\n",
    "- in order to export OSM as CSV for SQL imgration later, I need to store each tag's information in separate csv file.\n",
    "- especially, tag element has to be tracked which node or way element it belongs to.\n",
    "- also, nd element has to be tracked as well about which way element it belongs to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import schema\n",
    "import codecs\n",
    "import cerberus\n",
    "\n",
    "SCHEMA = schema.Schema\n",
    "\n",
    "NODES_PATH = \"nodes.csv\"\n",
    "NODE_TAGS_PATH = \"nodes_tags.csv\"\n",
    "WAYS_PATH = \"ways.csv\"\n",
    "WAY_NODES_PATH = \"ways_nodes.csv\"\n",
    "WAY_TAGS_PATH = \"ways_tags.csv\"\n",
    "\n",
    "# this regex finds a string that contains problematic characters\n",
    "PROBLEMCHARS = re.compile(r'[=\\+\\/\\&\\<\\>\\;\\'\\\"\\?\\%\\#\\$\\@\\,\\. \\t\\r\\n]')\n",
    "LOWER_COLON = re.compile(r'^([a-z|_]+)+:([a-z|_]+)+')\n",
    "\n",
    "NODE_FIELDS = ['id', 'lat', 'lon', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "NODE_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_FIELDS = ['id', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "WAY_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_NODES_FIELDS = ['id', 'node_id', 'position']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- helper functions are defined for code readibility and reproducability.\n",
    "- shape_tag_element function\n",
    "  - this is where update for inconsistent tag's value occurs\n",
    "  - if key contains \":\", string before \":\" is the type of the tag, and string after \":\" becomes the key.\n",
    "  - if there is no \":\" in key, tag type becomes 'regular'\n",
    "  - this function returns a dictionary which contains..\n",
    "    - key, type(tag type), id(reference which the tag belongs to node / way element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shape_tag_element(tag_element, ref_id, default_tag_type):\n",
    "    tag_attribs = {}\n",
    "\n",
    "    key = tag_element.attrib['k']\n",
    "    value = tag_element.attrib['v']\n",
    "\n",
    "    if re.search(PROBLEMCHARS, key):\n",
    "        return None\n",
    "\n",
    "    key_match = re.search(LOWER_COLON, key)\n",
    "    if key_match:\n",
    "        key_type = key_match.group(1)\n",
    "        key_index = (key.index(key_type) + len(key_type))+1         \n",
    "\n",
    "        tag_attribs['key'] = key[key_index: ]\n",
    "        tag_attribs['type'] = key_type\n",
    "    else:\n",
    "        tag_attribs['key'] = key\n",
    "        tag_attribs['type'] = default_tag_type\n",
    "\n",
    "    tag_attribs['id'] = ref_id\n",
    "\n",
    "    '''\n",
    "    this is where tag value update will happen\n",
    "    '''\n",
    "    if tag_attribs['key'] == 'maxspeed' or tag_attribs['key'] == 'minspeed':\n",
    "        value = update_speed_unit(value)\n",
    "    elif tag_attribs['key'] == 'phone':\n",
    "        value = update_phone(value)\n",
    "    elif tag_attribs['key'] == 'street':\n",
    "        value = update_street_name(value)\n",
    "        \n",
    "    if value == None:\n",
    "        return None\n",
    "    \n",
    "    tag_attribs['value'] = value\n",
    "\n",
    "    return tag_attribs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- shape_tag_elements function\n",
    "  - this function simply iterate through all tags belonging to a node or way element and make a list of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shape_tag_elements(tags, parent_element, default_tag_type):\n",
    "    for tag_element in parent_element.iter('tag'):\n",
    "        tag_attribs = shape_tag_element(tag_element, \\\n",
    "                                        parent_element.attrib['id'], \\\n",
    "                                        default_tag_type)\n",
    "\n",
    "        if tag_attribs != None:\n",
    "            tags.append(tag_attribs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- shape_common_for_node_and_way function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shape_common_for_node_and_way(common_attribs, element):\n",
    "    common_attribs['id'] = int(element.attrib['id'])\n",
    "    common_attribs['uid'] = int(element.attrib['uid'])\n",
    "    common_attribs['changeset'] = int(element.attrib['changeset'])\n",
    "    common_attribs['user'] = element.attrib['user']\n",
    "    common_attribs['version'] = element.attrib['version']\n",
    "    common_attribs['timestamp'] = element.attrib['timestamp']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- shape_element function\n",
    "  - this function identifies node and way elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shape_nd_element(nd_element, ref_id, position):\n",
    "    nd_attribs = {}\n",
    "\n",
    "    nd_attribs['id'] = ref_id\n",
    "    nd_attribs['node_id'] = nd_element.attrib['ref']\n",
    "    nd_attribs['position'] = position\n",
    "\n",
    "    return nd_attribs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def shape_element(element, key_error_count, problem_chars=PROBLEMCHARS, default_tag_type='regular'):\n",
    "    node_attribs = {}\n",
    "    way_attribs = {}\n",
    "    way_nodes = []\n",
    "    tags = []\n",
    "\n",
    "    if element.tag == 'node':\n",
    "        try:\n",
    "            shape_common_for_node_and_way(node_attribs, element)\n",
    "            node_attribs['lat'] = float(element.attrib['lat'])\n",
    "            node_attribs['lon'] = float(element.attrib['lon'])\n",
    "\n",
    "            shape_tag_elements(tags, element, default_tag_type)\n",
    "            return {'node': node_attribs, 'node_tags': tags}\n",
    "        except KeyError as e:\n",
    "            key_error_count += 1\n",
    "    \n",
    "    elif element.tag == 'way':\n",
    "        try:\n",
    "            shape_common_for_node_and_way(way_attribs, element)\n",
    "            shape_tag_elements(tags, element, default_tag_type)\n",
    "\n",
    "            nd_position = 0\n",
    "            for nd_element in element.iter('nd'):\n",
    "                nd_attribs = shape_nd_element(nd_element, \\\n",
    "                                              int(element.attrib['id']), \\\n",
    "                                              nd_position)\n",
    "                way_nodes.append(nd_attribs)\n",
    "                nd_position += 1\n",
    "\n",
    "            return {'way': way_attribs, 'way_nodes': way_nodes, 'way_tags': tags}\n",
    "        except KeyError as e:\n",
    "            key_error_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class UnicodeDictWriter(csv.DictWriter, object):\n",
    "    \"\"\"Extend csv.DictWriter to handle Unicode input\"\"\"\n",
    "\n",
    "    def writerow(self, row):\n",
    "        super(UnicodeDictWriter, self).writerow({\n",
    "            k: (v.encode('utf-8') if isinstance(v, unicode) else v) for k, v in row.iteritems()\n",
    "        })\n",
    "\n",
    "    def writerows(self, rows):\n",
    "        for row in rows:\n",
    "            self.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_element(osm_file, tags=('node', 'way', 'relation')):\n",
    "    \"\"\"Yield element if it is the right type of tag\"\"\"\n",
    "\n",
    "    context = ET.iterparse(osm_file, events=('start', 'end'))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end' and elem.tag in tags:\n",
    "            yield elem\n",
    "            root.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Storing each elements' data into separate file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_map(file_in):\n",
    "    with codecs.open(NODES_PATH, 'w') as nodes_file, \\\n",
    "         codecs.open(NODE_TAGS_PATH, 'w') as nodes_tags_file, \\\n",
    "         codecs.open(WAYS_PATH, 'w') as ways_file, \\\n",
    "         codecs.open(WAY_NODES_PATH, 'w') as way_nodes_file, \\\n",
    "         codecs.open(WAY_TAGS_PATH, 'w') as way_tags_file:\n",
    "\n",
    "        nodes_writer = UnicodeDictWriter(nodes_file, NODE_FIELDS)\n",
    "        node_tags_writer = UnicodeDictWriter(nodes_tags_file, NODE_TAGS_FIELDS)\n",
    "        ways_writer = UnicodeDictWriter(ways_file, WAY_FIELDS)\n",
    "        way_nodes_writer = UnicodeDictWriter(way_nodes_file, WAY_NODES_FIELDS)\n",
    "        way_tags_writer = UnicodeDictWriter(way_tags_file, WAY_TAGS_FIELDS)\n",
    "\n",
    "        '''\n",
    "        nodes_writer.writeheader()\n",
    "        node_tags_writer.writeheader()\n",
    "        ways_writer.writeheader()\n",
    "        way_nodes_writer.writeheader()\n",
    "        way_tags_writer.writeheader()\n",
    "        '''\n",
    "\n",
    "        validator = cerberus.Validator()\n",
    "        key_error_count = 0\n",
    "\n",
    "        for element in get_element(file_in, tags=('node', 'way')):\n",
    "            el = shape_element(element, key_error_count)\n",
    "            if el:\n",
    "                if element.tag == 'node':\n",
    "                    nodes_writer.writerow(el['node'])\n",
    "                    node_tags_writer.writerows(el['node_tags'])\n",
    "                elif element.tag == 'way':\n",
    "                    ways_writer.writerow(el['way'])\n",
    "                    way_nodes_writer.writerows(el['way_nodes'])\n",
    "                    way_tags_writer.writerows(el['way_tags'])\n",
    "        \n",
    "        print 'number of node or way element that encountered KeyError {}'.format(key_error_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of node or way element that encountered KeyError 0\n"
     ]
    }
   ],
   "source": [
    "process_map(OSM_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Importing CSV into SQLite\n",
    "\n",
    "Database Schema for SQLite3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sql\n",
    "CREATE TABLE nodes (\n",
    "    id INTEGER PRIMARY KEY NOT NULL,\n",
    "    lat REAL,\n",
    "    lon REAL,\n",
    "    user TEXT,\n",
    "    uid INTEGER,\n",
    "    version INTEGER,\n",
    "    changeset INTEGER,\n",
    "    timestamp TEXT\n",
    ");\n",
    "\n",
    "CREATE TABLE nodes_tags (\n",
    "    id INTEGER,\n",
    "    key TEXT,\n",
    "    value TEXT,\n",
    "    type TEXT,\n",
    "    FOREIGN KEY (id) REFERENCES nodes(id)\n",
    ");\n",
    "\n",
    "CREATE TABLE ways (\n",
    "    id INTEGER PRIMARY KEY NOT NULL,\n",
    "    user TEXT,\n",
    "    uid INTEGER,\n",
    "    version TEXT,\n",
    "    changeset INTEGER,\n",
    "    timestamp TEXT\n",
    ");\n",
    "\n",
    "CREATE TABLE ways_tags (\n",
    "    id INTEGER NOT NULL,\n",
    "    key TEXT NOT NULL,\n",
    "    value TEXT NOT NULL,\n",
    "    type TEXT,\n",
    "    FOREIGN KEY (id) REFERENCES ways(id)\n",
    ");\n",
    "\n",
    "CREATE TABLE ways_nodes (\n",
    "    id INTEGER NOT NULL,\n",
    "    node_id INTEGER NOT NULL,\n",
    "    position INTEGER NOT NULL,\n",
    "    FOREIGN KEY (id) REFERENCES ways(id),\n",
    "    FOREIGN KEY (node_id) REFERENCES nodes(id)\n",
    ");\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "importing data from csv into the tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`\n",
    "sqlite> .tables\n",
    "nodes       nodes_tags  ways        ways_nodes  ways_tags\n",
    "sqlite> .mode csv\n",
    "sqlite> .import ./nodes.csv nodes\n",
    "sqlite> .import ./nodes_tags.csv nodes_tags\n",
    "sqlite> .import ./ways.csv ways\n",
    "sqlite> .import ./ways_nodes.csv ways_nodes\n",
    "sqlite> .import ./ways_tags.csv ways_tags\n",
    "`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "checking first few lines for each table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sql\n",
    "sqlite> SELECT * FROM nodes LIMIT 2;\n",
    "25832758|48.4364741|-123.3129318|CoreyBurger|6009  |4|9689672|2011-10-29T23:34:53Z\n",
    "25839536|48.435199 |-123.3288383|alester    |307202|3|9568618|2011-10-16T00:43:37Z\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sql\n",
    "sqlite> SELECT * FROM nodes_tags LIMIT 2;\n",
    "27170286|created_by|YahooApplet 1.0|regular\n",
    "30139083|highway   |traffic_signals|regular\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sql\n",
    "sqlite> SELECT * FROM ways LIMIT 2;\n",
    "4388496|alester|307202 |2|8212025 |2011-05-22T02:31:47Z\n",
    "4736718|Madrona|3305376|4|34783992|2015-10-21T17:39:39Z\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sql\n",
    "sqlite> SELECT * FROM ways_nodes LIMIT 2;\n",
    "4388496|1295593467|0\n",
    "4388496|26793412  |1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sql\n",
    "sqlite> SELECT * FROM ways_tags LIMIT 2;\n",
    "4388496|name   |Arden Road |regular\n",
    "4388496|highway|residential|regular\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`\n",
    "sqlite> .save wrangle_us.db\n",
    "sqlite> .mode column\n",
    "sqlite> .headers on\n",
    "`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Perform some queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 7-1. Number of contributors to node and way elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sql\n",
    "sqlite> \n",
    "SELECT COUNT(DISTINCT user) as num_of_user\n",
    "FROM \n",
    "    (\n",
    "     SELECT user \n",
    "     FROM nodes \n",
    "     UNION ALL \n",
    "         SELECT user \n",
    "         FROM ways\n",
    "    )\n",
    ";\n",
    "   \n",
    "num_of_user\n",
    "-----------\n",
    "631  \n",
    "```\n",
    "\n",
    "**As expected lots of user (631) did participated in to collect and input data to build a map data for this huge city**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7-2. Top 10  contributors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sql\n",
    "sqlite> \n",
    "SELECT DISTINCT user, COUNT(*) as num_of_contrib\n",
    "FROM\n",
    "\t(\n",
    "\t SELECT user \n",
    "\t FROM nodes \n",
    "\t UNION ALL \n",
    "\t \tSELECT user \n",
    "\t\tFROM ways\n",
    "\t)\n",
    "GROUP BY user\n",
    "ORDER BY num_of_contrib DESC\n",
    "LIMIT 10;\n",
    "   \n",
    "user        num_of_contrib\n",
    "----------  --------------\n",
    "Glassman    2602          \n",
    "SeattleImp  1472          \n",
    "tylerritch  1316          \n",
    "woodpeck_f  1149          \n",
    "alester     713           \n",
    "Omnific     628           \n",
    "Glassman_I  453           \n",
    "CarniLvr79  415           \n",
    "STBrenden   415           \n",
    "Brad Meteo  373   \n",
    "```\n",
    "\n",
    "**It looks like Glassman did make huge contribution.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7-3. The most included tag type under node and way respectively\n",
    "\n",
    "```sql\n",
    "sqlite> \n",
    "SELECT type as type_in_node, COUNT(*) as num\n",
    "FROM nodes_tags\n",
    "GROUP BY type\n",
    "ORDER BY num DESC\n",
    "LIMIT 2;\n",
    "\n",
    "type_in_node  num       \n",
    "------------  ----------\n",
    "regular       1191      \n",
    "addr          978  \n",
    "```\n",
    "\n",
    "**The \"regular\" is the most included tag type. It is not surprising since regular tag is something which doesn't provide additional information included in the key. There are not many tags available which come with additional information. The addr tag is the second most popular one. It looks reseonable to have lots of address information to describe a map.**\n",
    "\n",
    "```sql\n",
    "sqlite>\n",
    "SELECT type as type_in_way, COUNT(*) as num\n",
    "FROM ways_tags\n",
    "GROUP BY type\n",
    "ORDER BY num DESC\n",
    "LIMIT 2;\n",
    "\n",
    "type_in_way   num       \n",
    "------------  ----------\n",
    "regular       3518      \n",
    "tiger         1560\n",
    "```\n",
    "\n",
    "**The tag type, \"tiger\" is the most included tag type after regular type. I have searched what this type of tag is, and I found the tiger tag type means** *\"The string 'tiger' is the prefix of keys that are part of the TIGER import of the United States.\"*. **It looks like a sort of imported tag information from other map's dataset. This raised another question if this tag type is used to form the node elements as well.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7-4. tiger type tag looks popular in way element, how about in node element?\n",
    "\n",
    "```sql\n",
    "sqlite> \n",
    "SELECT type as type_in_node, COUNT(*) as num\n",
    "FROM nodes_tags\n",
    "GROUP BY type\n",
    "ORDER BY num DESC\n",
    "\n",
    "type_in_node  num       \n",
    "------------  ----------\n",
    "regular       1191      \n",
    "addr          978       \n",
    "gtfs          26        \n",
    "gnis          23        \n",
    "sdot          20        \n",
    "source        17        \n",
    "is_in         3         \n",
    "name          3         \n",
    "seamark       3         \n",
    "checked_exis  2         \n",
    "disused       1         \n",
    "toilets       1\n",
    "```\n",
    "\n",
    "**This looked strange at first because the tiger tag type is never included in node elements, so I looked at the documentation. This is what I found.** *\"In 2010 tiger tags were removed from about 177 million nodes, affected tags were: tiger:county=*, tiger:tlid=* and tiger:upload_uuid=*. See TIGER fixup/node tags for details. As a result, tiger keys are now almost exclusively found on ways.\"*  **now it makes sense why tiger tag doesn't appear at all."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7-5.  Top 5 tag keys whose type is \"regular\" under node and way respectively, and in combination of the two.\n",
    "\n",
    "```sql\n",
    "sqlite>\n",
    "SELECT key as key_in_node, COUNT(*) as num\n",
    "FROM nodes_tags\n",
    "WHERE type='regular'\n",
    "GROUP BY key\n",
    "ORDER BY num DESC\n",
    "LIMIT 5;\n",
    "\n",
    "key_in_node  num       \n",
    "-----------  ----------\n",
    "source       420       \n",
    "created_by   137       \n",
    "highway      100       \n",
    "power        90        \n",
    "name         68  \n",
    "```\n",
    "\n",
    "**Source, created_by, and name don't give much information to understand. However, the count of highway tag explains that lots of nodes are built around highway. Also, lots of power tags are included to descrige node elements. Let me look more detail what values for power tags are used.**\n",
    "\n",
    "```sql\n",
    "SELECT value as value_in_power, COUNT(*) as num\n",
    "FROM nodes_tags\n",
    "WHERE type='regular'\n",
    "AND key='power'\n",
    "ORDER BY num DESC;\n",
    "\n",
    "value_in_power  num       \n",
    "--------------  ----------\n",
    "pole            90   \n",
    "```\n",
    "\n",
    "**Surprisingly, the only one value, \"pole\", is used under \"power\" tag key. This is what pole is according to the documentation.** *Poles supporting low to medium voltage lines (power=minor_line) and high voltage lines (power=line) up to 161,000 volts (161 kV).* **I don't quiet understand why the only pole value is included, it makes me to think this information is incomplete**\n",
    "\n",
    "```sql\n",
    "sqlite>\n",
    "SELECT key as key_in_way, COUNT(*) as num\n",
    "FROM ways_tags\n",
    "WHERE type='regular'\n",
    "GROUP BY key\n",
    "ORDER BY num DESC\n",
    "LIMIT 5;\n",
    "\n",
    "key_in_way  num       \n",
    "----------  ----------\n",
    "building    683       \n",
    "highway     615       \n",
    "source      561       \n",
    "name        399       \n",
    "service     107   \n",
    "```\n",
    "\n",
    "**Building, highway, and service are informative data to describe ways. **\n",
    "\n",
    "```sql\n",
    "sqlite>\n",
    "SELECT key, COUNT(*) as num\n",
    "FROM \n",
    "    (\n",
    "     SELECT key\n",
    "     FROM nodes_tags \n",
    "     UNION ALL \n",
    "        SELECT key \n",
    "        FROM ways_tags\n",
    "        WHERE type='regular'\n",
    "    )\n",
    "GROUP BY key\n",
    "ORDER BY num DESC\n",
    "LIMIT 5;\n",
    "\n",
    "key         num       \n",
    "----------  ----------\n",
    "source      981       \n",
    "highway     715       \n",
    "building    685       \n",
    "name        467       \n",
    "housenumbe  260\n",
    "```\n",
    "\n",
    "**For both way and node elements, highway, building, and housenumber seems like to be used most frequently. It looks a bit strange the number of housenumber is a way smaller than the number of buildings though. I found that \"addr:housenumber\" tag also describes housenumber information, so it might be possible to have same informational data in two different tags.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While doing this project, I have learned the followings.\n",
    "- How to investigate XML based dataset\n",
    "- How to parse XML elements with their attributes\n",
    "- How to make inconsistent data in the XML to be consistent\n",
    "- How to export re-organized data into CSV format.\n",
    "- How to export CSVs into SQLite based RDB.\n",
    "- How to run SQL syntax queries to investigate the dataset more expressively and efficiently.\n",
    "\n",
    "The OSM data gives a lot of information, but the information is formed by human being not machine generated. It means it contains lots of inconsistent and not well-organized data format sometimes. In order to find more meaningful information out of the dataset, it has to be cleaned so that data analysts can trust it. I think I became more confident to achieve converting inconsistent data to consistent data through this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:DAND]",
   "language": "python",
   "name": "conda-env-DAND-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
